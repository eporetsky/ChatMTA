{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4617720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac807bb",
   "metadata": {},
   "source": [
    "# Open the manuscript dictionaries to get DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e126fdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_input/scipdf.pkl', 'rb') as handle:\n",
    "    pdf_dict = pickle.load(handle)\n",
    "\n",
    "pdf_doi_dict = {}\n",
    "for pdf_name in pdf_dict.keys():\n",
    "    pdf_doi_dict[pdf_name.replace(\".pdf\", \"\")] = pdf_dict[pdf_name][\"doi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419042fc",
   "metadata": {},
   "source": [
    "# Extract all MTA information from the 36 manuscripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8916d4fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "    marker_results = pd.DataFrame()\n",
    "    fail_list = []\n",
    "\n",
    "    for key in pdf_dict.keys():\n",
    "        \n",
    "        time.sleep(2)\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        key = key.replace(\".pdf\", \"\")\n",
    "        db = FAISS.load_local(\"data_faiss/faiss_chunked/faiss_db_1000/{}\".format(key), embeddings, allow_dangerous_deserialization=True)\n",
    "        retriever = db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                    search_kwargs={\"score_threshold\": 0.5, \"k\": 25})\n",
    "\n",
    "        query = \"\"\"Find all the names of significant QTLs, QTNs, MTAs, SNPs, SRR regions or GWAS marker names mentioned in the manuscript. \\\n",
    "                For each significant marker you find, find which trait or condition it is associated with, or which trait or condition was \\\n",
    "                used to genetically map to this trait. If there are multiple traits or conditions associated with a single marker, combine them. \n",
    "\n",
    "                Important - Respond in JSON format only, following the schema below:\n",
    "                    ```json\n",
    "                    {\n",
    "                    \"marker\": string  // QTL, QTN, MTA, SNP, SRR regions or GWAS marker name\n",
    "                    \"trait_full\": string  // full, non-abbreviated, names of all traits associated with the given marker\n",
    "                    \"trait_abv\": string  // abbreviated names of all traits associated with the given marker\n",
    "                    \"chromosome\": string // chromosome name and location information, if available. NaN if not found\n",
    "                    \"genomic_range\": string // range of genomic region the marker was mapped to, if available. NaN if not found\n",
    "                    }\n",
    "                    ```\n",
    "                \"\"\"\n",
    "        \n",
    "        llm = ChatOpenAI(model_name=model) \n",
    "        qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, temperature=0.7)\n",
    "        marker_response = qa(query)\n",
    "\n",
    "        try:\n",
    "            response_string = marker_response['result']\n",
    "            response_string = response_string.split(\"```\")[1] if \"```\" in response_string else response_string\n",
    "            response_string = response_string.replace(\"```\", \"\")\n",
    "            response_string = response_string.replace(\"json\\n\", \"\")\n",
    "            response_string = response_string.replace(\"}\\n{\", \"},\\n{\")\n",
    "            response_string = response_string.replace(\"\\n}\\n}\\n\", \"\\n}\\n\")\n",
    "            response_string = response_string.replace(\"}\\n\", \"}\")\n",
    "\n",
    "            if \"[\" not in response_string:\n",
    "                response_string = \"[\" + response_string\n",
    "            if \"]\" not in response_string:\n",
    "                response_string = response_string + \"]\"\n",
    "\n",
    "            # Parse the JSON format and turn it into a pandas dataframe\n",
    "            response_json = json.loads(response_string)\n",
    "            tmp_df = pd.DataFrame(response_json)\n",
    "\n",
    "            # Add the PDF and DOI IDs so it is easier to keep track of\n",
    "            tmp_df[\"pdf\"] = key\n",
    "            tmp_df[\"doi\"] = pdf_doi_dict[key]\n",
    "            marker_results = pd.concat([marker_results, tmp_df])\n",
    "            print(\"success,\"+key)\n",
    "        except:\n",
    "            print(\"fail,\"+key)\n",
    "            fail_list.append([key, marker_response['result']])\n",
    "    marker_results.to_csv(f\"data_output/markers/36.markers.{model}.tsv\".format(key), sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab5f119",
   "metadata": {},
   "source": [
    "# Short results over all papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_markers = pd.read_csv(\"data_figures/36.markers.curated.tsv\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "true_markers = true_markers.groupby(\"doi\").count().reset_index()[[\"doi\", \"marker\"]]\n",
    "\n",
    "# Sum the 'correct' column because some predictions contain multiple markers that are all counted\n",
    "pred_markers = pd.read_csv(\"data_figures/36.markers.tsv\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "pred_markers = pred_markers.drop_duplicates([\"Model\", \"doi\", \"marker\"])\n",
    "pred_markers = pred_markers.groupby([\"Model\", \"doi\"]).sum().reset_index()[[\"Model\", \"doi\", \"correct\"]]\n",
    "results = pred_markers.merge(true_markers, on=\"doi\", how=\"outer\")\n",
    "\n",
    "results = results.fillna(0) # out join with missing results returns NaN\n",
    "results['% correct'] = results[\"correct\"] / results[\"marker\"] * 100\n",
    "\n",
    "plt.rcParams.update({'font.weight': 'bold', 'font.size': 13, \n",
    "                     'axes.labelweight': 'bold', 'axes.titleweight': 'bold'})\n",
    "fig, ax = plt.subplots(figsize=(3, 4))\n",
    "\n",
    "print(results[[\"Model\", \"% correct\"]].groupby(\"Model\").mean())\n",
    "sns.barplot(data=results, x=\"Model\", y= \"% correct\", color=\"black\")\n",
    "sns.swarmplot(data=results, x=\"Model\", y= \"% correct\", color=\"orange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e2b3fd",
   "metadata": {},
   "source": [
    "# Analyze a single paper with different chunk sizes and K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"gpt-3.5-turbo\", \"gpt-4\"]:\n",
    "    marker_results = pd.DataFrame()\n",
    "    fail_list = []\n",
    "    key = \"s00122-022-04109-9.pdf\"\n",
    "\n",
    "    for size in [250,500,750,1000]:\n",
    "        for k in [5,10,15,20,25]:\n",
    "            for rep in [1,2,3,4]:\n",
    "                time.sleep(2)\n",
    "                embeddings = OpenAIEmbeddings()\n",
    "                key = key.replace(\".pdf\", \"\")\n",
    "                db = FAISS.load_local(\"data_faiss/faiss_chunked/faiss_db_{}/{}\".format(size, key), embeddings)\n",
    "                retriever = db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                            search_kwargs={\"score_threshold\": 0.5, \"k\": k})\n",
    "                \n",
    "                query = \"\"\"Find all the names of significant QTLs, QTNs, MTAs, SNPs, SRR regions or GWAS marker names mentioned in the manuscript. \\\n",
    "                        For each significant marker you find, find which trait or condition it is associated with, or which trait or condition was \\\n",
    "                        used to genetically map to this trait. If there are multiple traits or conditions associated with a single marker, combine them. \n",
    "\n",
    "                        Important - Respond in JSON format only, following the schema below:\n",
    "                            ```json\n",
    "                            {\n",
    "                            \"marker\": string  // QTL, QTN, MTA, SNP, SRR regions or GWAS marker name\n",
    "                            \"trait_full\": string  // full, non-abbreviated, names of all traits associated with the given marker\n",
    "                            \"trait_abv\": string  // abbreviated names of all traits associated with the given marker\n",
    "                            \"chromosome\": string // chromosome name and location information, if available. NaN if not found\n",
    "                            \"genomic_range\": string // range of genomic region the marker was mapped to, if available. NaN if not found\n",
    "                            }\n",
    "                            ```\n",
    "                        \"\"\"\n",
    "\n",
    "                # Uncommend the LLM model you want to use for the RAG chain\n",
    "                #llm = ChatOpenAI(model_name='gpt-3.5-turbo-1106')\n",
    "                llm = ChatOpenAI(model_name='gpt-4') \n",
    "                qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, temperature=0.7)\n",
    "                marker_response = qa(query)\n",
    "                \n",
    "                # Correct the returned JSON format based on observed errors\n",
    "                try:\n",
    "                    response_string = marker_response['result']\n",
    "                    response_string = response_string.split(\"```\")[1] if \"```\" in response_string else response_string\n",
    "                    response_string = response_string.replace(\"```\", \"\")\n",
    "                    response_string = response_string.replace(\"json\\n\", \"\")\n",
    "                    response_string = response_string.replace(\"}\\n{\", \"},\\n{\")\n",
    "                    response_string = response_string.replace(\"\\n}\\n}\\n\", \"\\n}\\n\")\n",
    "                    response_string = response_string.replace(\"}\\n\", \"}\")\n",
    "                    \n",
    "                    if \"[\" not in response_string:\n",
    "                        response_string = \"[\" + response_string\n",
    "                    if \"]\" not in response_string:\n",
    "                        response_string = response_string + \"]\"\n",
    "                    \n",
    "                    # Parse the JSON format and turn it into a pandas dataframe\n",
    "                    response_json = json.loads(response_string)\n",
    "                    tmp_df = pd.DataFrame(response_json)\n",
    "                    \n",
    "                    # Add the PDF and DOI IDs so it is easier to keep track of\n",
    "                    tmp_df[\"pdf\"] = key\n",
    "                    tmp_df[\"doi\"] = pdf_doi_dict[key]\n",
    "                    tmp_df[\"k\"] = k\n",
    "                    tmp_df[\"rep\"] = rep\n",
    "                    tmp_df[\"size\"] = size\n",
    "                    marker_results = pd.concat([marker_results, tmp_df])\n",
    "                except:\n",
    "                    fail_list.append([key, size, k, rep, marker_response['result']])\n",
    "    marker_results.to_csv(f\"data_output/markers/p10.markers.{model}.tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce9a47",
   "metadata": {},
   "source": [
    "# Make plots for the different k and chunk size comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_markers = pd.read_csv(\"data_figures/36.markers.curated.tsv\", sep=\"\\t\", encoding = \"ISO-8859-1\")\n",
    "true_markers = true_markers.groupby(\"doi\").count().reset_index()[[\"doi\", \"marker\"]]\n",
    "n_markers = true_markers[true_markers[\"doi\"]==\"10.1007/s00122-022-04109-9\"][\"marker\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beea856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.weight': 'bold', 'font.size': 13, \n",
    "                     'axes.labelweight': 'bold', 'axes.titleweight': 'bold'})\n",
    "fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "\n",
    "trait_results = pd.read_csv(\"data_figures/p10.marekrs.gpt-3.5-turbo.tsv\" ,sep=\"\\t\")\n",
    "trait_results = trait_results[trait_results[\"correct\"]==1]\n",
    "trait_results = trait_results[[\"k\", \"rep\", \"size\", \"correct\"]].groupby([\"k\", \"rep\", \"size\"]).sum().reset_index()\n",
    "trait_results[\"% correct\"] = trait_results[\"correct\"] / n_markers * 100\n",
    "\n",
    "trait_results.columns = [\"Top-k Size\", \"rep\", \"Chunk Size\", \"correct\",\"% correct\"]\n",
    "ax = sns.barplot(data=trait_results, x=\"Chunk Size\", y=\"% correct\", hue=\"Top-k Size\", errorbar=\"sd\")\n",
    "ax.set_title(\"GPT-3.5\")\n",
    "plt.legend(loc='upper right', title=\"Top-k Size\", prop={'size': 10})\n",
    "plt.ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.weight': 'bold', 'font.size': 13, \n",
    "                     'axes.labelweight': 'bold', 'axes.titleweight': 'bold'})\n",
    "fig, ax = plt.subplots(figsize=(4.5, 3))\n",
    "\n",
    "trait_results = pd.read_csv(\"data_figures/p10.markers.gpt-4.tsv\" ,sep=\"\\t\")\n",
    "trait_results = trait_results[trait_results[\"correct\"]==1]\n",
    "trait_results = trait_results[[\"k\", \"rep\", \"size\", \"correct\"]].groupby([\"k\", \"rep\", \"size\"]).sum().reset_index()\n",
    "trait_results[\"% correct\"] = trait_results[\"correct\"] / n_markers * 100\n",
    "\n",
    "trait_results.columns = [\"Top-k Size\", \"rep\", \"Chunk Size\", \"correct\",\"% correct\"]\n",
    "ax = sns.barplot(data=trait_results, x=\"Chunk Size\", y=\"% correct\", hue=\"Top-k Size\", errorbar=\"sd\")\n",
    "ax.set_title(\"GPT-4\")\n",
    "ax.get_legend().remove()\n",
    "plt.ylim(0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
